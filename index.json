[{"content":"I build AI automation pipelines to make your business more productive and save you money.üë∑‚Äç‚ôÇÔ∏èü§ñ\nAs an AI Automation Engineer with a 10+ year background in software development, I specialize in one thing: creating powerful operational efficiencies. I design and implement custom AI-integrated pipelines that absorb manual work, optimize your processes, and free up your team to focus on what truly matters.\nWhen I\u0026rsquo;m not architecting automation, I\u0026rsquo;m usually singing with my guitar or exploring the creative limits of artificial intelligence. üé∏ü§ñ\n","date":"10 June 2025","externalUrl":null,"permalink":"/personal-website/","section":"","summary":"","title":"","type":"page"},{"content":"","date":"10 June 2025","externalUrl":null,"permalink":"/personal-website/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":" The Layers of AI: How Embeddings, MCP, and LangChain Work Together # If you‚Äôre a developer in the AI space, you‚Äôve probably felt like you‚Äôre drinking from a firehose. New models, frameworks, and protocols pop up every week. Three terms you‚Äôll often hear are Text Embeddings, the Model Context Protocol (MCP), and LangChain.\nAt first glance, they might seem like overlapping or competing ideas. But the truth is, they aren\u0026rsquo;t competitors at all. They are distinct, synergistic layers of the modern AI stack.\nUnderstanding how they fit together is the key to moving beyond simple chatbots and building truly powerful, data-aware applications. Let‚Äôs break it down with simple analogies.\nLayer 1: The Substance ‚Äî Text Embeddings # Imagine you need to give a computer a \u0026ldquo;feeling\u0026rdquo; for language. How would you explain that \u0026ldquo;king\u0026rdquo; and \u0026ldquo;queen\u0026rdquo; are related in the same way \u0026ldquo;man\u0026rdquo; and \u0026ldquo;woman\u0026rdquo; are? You can\u0026rsquo;t just give it a dictionary.\nThis is where embeddings come in.\nThe Analogy: Text embeddings are like GPS coordinates for meaning. An embedding model takes a piece of text‚Äîa word, a sentence, or an entire document‚Äîand converts it into a list of numbers called a vector. This vector is its unique address in a high-dimensional \u0026ldquo;meaning space.\u0026rdquo; Texts with similar meanings have coordinates that are close to each other.\nThis is the foundation of almost all modern AI. It‚Äôs how machines can search for concepts, not just keywords. It‚Äôs the substance that LLMs process.\nThe Takeaway: Embeddings translate fuzzy human language into a mathematical format that machines can understand and reason with. They are the raw material of meaning.\nLayer 2: The Universal Connector ‚Äî The Model Context Protocol (MCP) # Now that our AI can understand meaning, how do we connect it to the outside world? How do we give it access to our local files, a company database, or a third-party API like Jira without building a fragile, one-off integration for each?\nThis is the problem the standardized Model Context Protocol (MCP) is built to solve.\nThe Analogy: MCP is the USB-C port for AI‚ö°. Introduced as an open-source standard and championed by companies like Anthropic, MCP‚Äôs goal is to create a universal protocol for AI models (or any \u0026ldquo;host\u0026rdquo; application) to connect with any data source or tool (a \u0026ldquo;server\u0026rdquo;).\nBefore, if you wanted to connect your LLM to Notion, you needed a custom-built Notion adapter. If you also needed Salesforce, you had to build another one. It was a world of proprietary chargers.\nMCP creates a single, standard plug. A tool developer can expose their data via an MCP \u0026ldquo;server,\u0026rdquo; and any AI model or application that speaks MCP can instantly connect to it. This makes the ecosystem vastly more interoperable and scalable.\nThe Takeaway: MCP isn‚Äôt the AI itself; it‚Äôs the standard communication channel that allows an AI to securely and reliably get context from the outside world.\nLayer 3: The Brains of the Operation ‚Äî LangChain # We have our substance (embeddings) and a standard port to connect tools (MCP). But what actually decides what to do? What asks the question, fetches the data, thinks about it, and takes the next step?\nThis is where an orchestration framework like LangChain comes in.\nThe Analogy: If MCP is the USB-C port, LangChain is the Operating System. Your computer‚Äôs OS uses the standard USB-C ports to manage your keyboard, webcam, and external drive. But it does more than just connect them; it orchestrates them to run a complex application like a video conference. The OS handles the logic, and the ports handle the connection.\nThis is exactly what LangChain does for AI.\nOrchestration: LangChain provides the cognitive architecture for building multi-step applications. For example, an \u0026ldquo;agent\u0026rdquo; built with LangChain might perform a loop:\nThink: The LLM decides what tool to use. Act: It uses MCP to connect to that tool (e.g., query a Salesforce database). Observe: It gets the result back from the tool. Repeat: It feeds the result back into the LLM to decide the next step. MCP handles the \u0026ldquo;Act\u0026rdquo; step‚Äôs connection, but LangChain manages the entire reasoning loop. Abstraction: While MCP standardizes the connection to tools, you still have different LLM providers (OpenAI, Google, Anthropic) with their own APIs. LangChain abstracts this away. You can write your logic once and switch the underlying LLM with a single line of code.\nLangChain lets you focus on your application\u0026rsquo;s logic‚Äîthe \u0026ldquo;what\u0026rdquo;‚Äîwithout getting bogged down in the \u0026ldquo;how\u0026rdquo; of connecting each individual component.\nPutting It All Together # These three concepts form a perfect stack, each handling a different level of abstraction.\nLayer Concept Its Role in the Stack Analogy Orchestration LangChain The cognitive framework that decides what to do and in what order. The Operating System Connection MCP The standard port for connecting the AI to any tool or data source. The USB-C Port Substance Embeddings The mathematical representation of meaning that is being processed. GPS Coordinates So, is LangChain still relevant now that MCP exists? Absolutely. A standard for ports (MCP) doesn\u0026rsquo;t make an operating system (LangChain) obsolete; it makes it more powerful by simplifying one part of its job.\nThe future of AI development isn\u0026rsquo;t about a single tool winning out. It‚Äôs about building with layers of abstraction that work in harmony. By understanding the distinct roles of embeddings, MCP, and LangChain, you can build smarter, more scalable, and more robust AI applications.\n","date":"10 June 2025","externalUrl":null,"permalink":"/personal-website/posts/the-layers-of-ai/","section":"Posts","summary":"","title":"The Layers of AI: How Embeddings, MCP, and LangChain Work Together","type":"posts"},{"content":"","externalUrl":null,"permalink":"/personal-website/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/personal-website/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/personal-website/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","externalUrl":null,"permalink":"/personal-website/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"}]